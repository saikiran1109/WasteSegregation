{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Garbage Classification using VGG16","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.007556,"end_time":"2022-08-07T03:49:30.689802","exception":false,"start_time":"2022-08-07T03:49:30.682246","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Import Required Libraries","metadata":{"papermill":{"duration":0.006082,"end_time":"2022-08-07T03:49:30.702674","exception":false,"start_time":"2022-08-07T03:49:30.696592","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport random\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport zipfile\nimport sys\nimport time\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\n\nimport tensorflow.keras as keras\nimport tensorflow as tf\nimport re\n\nfrom PIL import Image\nfrom keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing import image\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Lambda\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nprint('setup successful!')","metadata":{"papermill":{"duration":6.310155,"end_time":"2022-08-07T03:49:37.019193","exception":false,"start_time":"2022-08-07T03:49:30.709038","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:32:21.783297Z","iopub.execute_input":"2022-08-07T13:32:21.783680Z","iopub.status.idle":"2022-08-07T13:32:21.792674Z","shell.execute_reply.started":"2022-08-07T13:32:21.783647Z","shell.execute_reply":"2022-08-07T13:32:21.791681Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Define Constants","metadata":{"papermill":{"duration":0.006287,"end_time":"2022-08-07T03:49:37.032227","exception":false,"start_time":"2022-08-07T03:49:37.025940","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Increasing the image size didn't result in increasing the training accuracy\nIMAGE_WIDTH = 224    \nIMAGE_HEIGHT = 224\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS = 3\n\n\n# Path where our data is located\nbase_path = \"../input/garbage-seg-10-v5/Garbage Seg 10 V5/\"\n\n# Dictionary to save our 12 classes\ncategories = {0: 'paper', 1: 'cardboard', 2: 'plastic', 3: 'metal', 4: 'food', 5: 'battery',\n              6: 'shoes', 7: 'clothes', 8: 'glass',9: 'medical'}\n\nprint('defining constants successful!')","metadata":{"papermill":{"duration":0.017624,"end_time":"2022-08-07T03:49:37.056304","exception":false,"start_time":"2022-08-07T03:49:37.038680","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:32:23.137504Z","iopub.execute_input":"2022-08-07T13:32:23.138222Z","iopub.status.idle":"2022-08-07T13:32:23.144975Z","shell.execute_reply.started":"2022-08-07T13:32:23.138185Z","shell.execute_reply":"2022-08-07T13:32:23.143841Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# Create DataFrame","metadata":{"papermill":{"duration":0.006157,"end_time":"2022-08-07T03:49:37.069260","exception":false,"start_time":"2022-08-07T03:49:37.063103","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"We want to create a data frame that has in one column the filenames of all our images and in the other column the corresponding category. \nWe Open the directories in the dataset one by one, save the filenames in the filenames_list and add the corresponding category in the categories_list","metadata":{"papermill":{"duration":0.006082,"end_time":"2022-08-07T03:49:37.081714","exception":false,"start_time":"2022-08-07T03:49:37.075632","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Add class name prefix to filename. So for example \"/paper104.jpg\" become \"paper/paper104.jpg\"\ndef add_class_name_prefix(df, col_name):\n    df[col_name] = df[col_name].apply(lambda x: x[:re.search(\"\\d\",x).start()] + '/' + x)\n    return df\n\n# list conatining all the filenames in the dataset\nfilenames_list = []\n# list to store the corresponding category, note that each folder of the dataset has one class of data\ncategories_list = []\n\nfor category in categories:\n    filenames = os.listdir(base_path + categories[category])\n    \n    filenames_list = filenames_list  +filenames\n    categories_list = categories_list + [category] * len(filenames)\n    \ndf = pd.DataFrame({\n    'filename': filenames_list,\n    'category': categories_list\n})\n\ndf = add_class_name_prefix(df, 'filename')\n\n# Shuffle the dataframe\ndf = df.sample(frac=1).reset_index(drop=True)\n\nprint('Number of Elements = ' , len(df))","metadata":{"papermill":{"duration":1.106705,"end_time":"2022-08-07T03:49:38.195585","exception":false,"start_time":"2022-08-07T03:49:37.088880","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:32:25.374211Z","iopub.execute_input":"2022-08-07T13:32:25.375123Z","iopub.status.idle":"2022-08-07T13:32:25.435191Z","shell.execute_reply.started":"2022-08-07T13:32:25.375074Z","shell.execute_reply":"2022-08-07T13:32:25.433692Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"papermill":{"duration":0.023952,"end_time":"2022-08-07T03:49:38.226142","exception":false,"start_time":"2022-08-07T03:49:38.202190","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:32:26.426753Z","iopub.execute_input":"2022-08-07T13:32:26.427353Z","iopub.status.idle":"2022-08-07T13:32:26.438126Z","shell.execute_reply.started":"2022-08-07T13:32:26.427318Z","shell.execute_reply":"2022-08-07T13:32:26.437143Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# see sample image, you can run the same cell again to get a different image\nrandom_row = random.randint(0, len(df)-1)\nsample = df.iloc[random_row]\nrandomimage = image.load_img(base_path +sample['filename'])\nprint(sample['filename'])\nplt.imshow(randomimage)","metadata":{"papermill":{"duration":0.251291,"end_time":"2022-08-07T03:49:38.483965","exception":false,"start_time":"2022-08-07T03:49:38.232674","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:32:26.895354Z","iopub.execute_input":"2022-08-07T13:32:26.896053Z","iopub.status.idle":"2022-08-07T13:32:27.094589Z","shell.execute_reply.started":"2022-08-07T13:32:26.895997Z","shell.execute_reply":"2022-08-07T13:32:27.093619Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# Viusalize the Categories Distribution","metadata":{"papermill":{"duration":0.007594,"end_time":"2022-08-07T03:49:38.499523","exception":false,"start_time":"2022-08-07T03:49:38.491929","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_visualization = df.copy()\n# Change the catgegories from numbers to names\ndf_visualization['category'] = df_visualization['category'].apply(lambda x:categories[x] )\n\ndf_visualization['category'].value_counts().plot.bar(x = 'count', y = 'category' )\n\nplt.xlabel(\"Garbage Classes\", labelpad=14)\nplt.ylabel(\"Images Count\", labelpad=14)\nplt.title(\"Count of images per class\", y=1.02);","metadata":{"papermill":{"duration":0.235036,"end_time":"2022-08-07T03:49:38.742382","exception":false,"start_time":"2022-08-07T03:49:38.507346","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:32:28.299522Z","iopub.execute_input":"2022-08-07T13:32:28.300194Z","iopub.status.idle":"2022-08-07T13:32:28.513618Z","shell.execute_reply.started":"2022-08-07T13:32:28.300157Z","shell.execute_reply":"2022-08-07T13:32:28.512555Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"# Create the model","metadata":{"papermill":{"duration":0.008181,"end_time":"2022-08-07T03:49:38.758699","exception":false,"start_time":"2022-08-07T03:49:38.750518","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"The steps are:\n1. Create an mobilenetv2 model without the last layer and load the ImageNet pretrained weights\n2. Add a pre-processing layer\n3. Add a pooling layer followed by a softmax layer at the end","metadata":{"papermill":{"duration":0.007737,"end_time":"2022-08-07T03:49:38.774833","exception":false,"start_time":"2022-08-07T03:49:38.767096","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nimport keras.applications.vgg16 as vgg16\nfrom tensorflow.keras.regularizers import l2\n\n\nvgg16_layer = VGG16(include_top = False, input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS),weights =\"imagenet\")\n\n# We don't want to train the imported weights\nvgg16_layer.trainable = False\n\n\nmodel = Sequential()\nmodel.add(keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n\n#create a custom layer to apply the preprocessing\ndef vgg16_preprocessing(img):\n  return vgg16.preprocess_input(img)\n\nmodel.add(Lambda(vgg16_preprocessing))\n\nmodel.add(vgg16_layer)\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\nmodel.add(Dense(len(categories),kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='softmax')) \n\nmodel.compile(loss='squared_hinge', optimizer='adam', metrics=['categorical_accuracy'])\n\nmodel.summary()","metadata":{"papermill":{"duration":3.599241,"end_time":"2022-08-07T03:49:42.381930","exception":false,"start_time":"2022-08-07T03:49:38.782689","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:34:41.746510Z","iopub.execute_input":"2022-08-07T13:34:41.747190Z","iopub.status.idle":"2022-08-07T13:34:42.081894Z","shell.execute_reply.started":"2022-08-07T13:34:41.747155Z","shell.execute_reply":"2022-08-07T13:34:42.080856Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"We will use the EarlyStopping call back to stop our training if the validation_accuray is not improving for a certain number of epochs.","metadata":{"papermill":{"duration":0.00996,"end_time":"2022-08-07T03:49:42.400974","exception":false,"start_time":"2022-08-07T03:49:42.391014","status":"completed"},"tags":[]}},{"cell_type":"code","source":"early_stop = EarlyStopping(patience = 2, verbose = 1, monitor='val_categorical_accuracy' , mode='max', min_delta=0.001, restore_best_weights = True)\n\ncallbacks = [early_stop]\n\nprint('Call Back Defined!')","metadata":{"papermill":{"duration":0.017671,"end_time":"2022-08-07T03:49:42.427308","exception":false,"start_time":"2022-08-07T03:49:42.409637","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:34:48.050129Z","iopub.execute_input":"2022-08-07T13:34:48.050489Z","iopub.status.idle":"2022-08-07T13:34:48.056940Z","shell.execute_reply.started":"2022-08-07T13:34:48.050459Z","shell.execute_reply":"2022-08-07T13:34:48.055947Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"# Split the Data Set","metadata":{"papermill":{"duration":0.008507,"end_time":"2022-08-07T03:49:42.445242","exception":false,"start_time":"2022-08-07T03:49:42.436735","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"We split the training set into three separate sets:\n\n1. **The training set:** used to train our model.\n1. **The validation set**: used to double check that our model is not overfitting the training set, i.e. it can also generalise to other data other than the train data\n1. **The Test set:** Used to estimate the accuracy of the model on new data other than the ones the model used for training\nFor a competition  or for some other cases, you can split the data only to training and validation sets in order to achieve the highest  possible accuracy, without the need to properly estimate how accurate the model really is.\n\nWe split the data set as follows: 80% train set, 10% cross_validation set, and 10% test set","metadata":{"papermill":{"duration":0.008455,"end_time":"2022-08-07T03:49:42.462317","exception":false,"start_time":"2022-08-07T03:49:42.453862","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Change the categories from numbers to names\ndf[\"category\"] = df[\"category\"].replace(categories) \n\n# We first split the data into two sets and then split the validate_df to two sets\ntrain_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\nvalidate_df, test_df = train_test_split(validate_df, test_size=0.5, random_state=42)\n\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\n\nprint('train size = ', total_validate , 'validate size = ', total_validate, 'test size = ', test_df.shape[0])","metadata":{"papermill":{"duration":0.025792,"end_time":"2022-08-07T03:49:42.496711","exception":false,"start_time":"2022-08-07T03:49:42.470919","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:34:50.044672Z","iopub.execute_input":"2022-08-07T13:34:50.045589Z","iopub.status.idle":"2022-08-07T13:34:50.063583Z","shell.execute_reply.started":"2022-08-07T13:34:50.045555Z","shell.execute_reply":"2022-08-07T13:34:50.062392Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"papermill":{"duration":0.020926,"end_time":"2022-08-07T03:49:42.526285","exception":false,"start_time":"2022-08-07T03:49:42.505359","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:34:51.234874Z","iopub.execute_input":"2022-08-07T13:34:51.235520Z","iopub.status.idle":"2022-08-07T13:34:51.246055Z","shell.execute_reply.started":"2022-08-07T13:34:51.235486Z","shell.execute_reply":"2022-08-07T13:34:51.244783Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{"papermill":{"duration":0.008711,"end_time":"2022-08-07T03:49:42.543737","exception":false,"start_time":"2022-08-07T03:49:42.535026","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"We will first create the training data generator, that will get the images from the input data directory to train on them. We will also create a generator for the validation set.\n\nApplying Data Augmentation on the training set was taking too long to be executed and the initial results didn't show much improvement than the results without augmentation, so I commented the augmentation to make the training faster. However fell free to uncomment the Data Augmentation lines in the following cell and play a bit with it.","metadata":{"papermill":{"duration":0.009258,"end_time":"2022-08-07T03:49:42.561796","exception":false,"start_time":"2022-08-07T03:49:42.552538","status":"completed"},"tags":[]}},{"cell_type":"code","source":"batch_size=64\n\ntrain_datagen = image.ImageDataGenerator()\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    base_path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","metadata":{"papermill":{"duration":6.722784,"end_time":"2022-08-07T03:49:49.293331","exception":false,"start_time":"2022-08-07T03:49:42.570547","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:35:11.191279Z","iopub.execute_input":"2022-08-07T13:35:11.191744Z","iopub.status.idle":"2022-08-07T13:35:11.354247Z","shell.execute_reply.started":"2022-08-07T13:35:11.191705Z","shell.execute_reply":"2022-08-07T13:35:11.353309Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"validation_datagen = image.ImageDataGenerator()\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    base_path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","metadata":{"papermill":{"duration":0.866066,"end_time":"2022-08-07T03:49:50.168747","exception":false,"start_time":"2022-08-07T03:49:49.302681","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:35:12.279022Z","iopub.execute_input":"2022-08-07T13:35:12.280922Z","iopub.status.idle":"2022-08-07T13:35:14.036602Z","shell.execute_reply.started":"2022-08-07T13:35:12.280874Z","shell.execute_reply":"2022-08-07T13:35:14.035678Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 20\nhistory = model.fit_generator(\n    train_generator, \n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size,\n    callbacks=callbacks\n)","metadata":{"papermill":{"duration":683.548527,"end_time":"2022-08-07T04:01:13.727248","exception":false,"start_time":"2022-08-07T03:49:50.178721","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:35:17.499502Z","iopub.execute_input":"2022-08-07T13:35:17.500175Z","iopub.status.idle":"2022-08-07T13:42:48.670176Z","shell.execute_reply.started":"2022-08-07T13:35:17.500139Z","shell.execute_reply":"2022-08-07T13:42:48.668323Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"model78.h5\")","metadata":{"papermill":{"duration":0.208273,"end_time":"2022-08-07T04:01:14.028088","exception":false,"start_time":"2022-08-07T04:01:13.819815","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:43:18.019249Z","iopub.execute_input":"2022-08-07T13:43:18.019609Z","iopub.status.idle":"2022-08-07T13:43:18.173879Z","shell.execute_reply.started":"2022-08-07T13:43:18.019577Z","shell.execute_reply":"2022-08-07T13:43:18.172642Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"model.save(\"model6904.h5\")","metadata":{"papermill":{"duration":21.707209,"end_time":"2022-08-07T04:01:35.843051","exception":false,"start_time":"2022-08-07T04:01:14.135842","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:43:18.949018Z","iopub.execute_input":"2022-08-07T13:43:18.949711Z","iopub.status.idle":"2022-08-07T13:43:19.062387Z","shell.execute_reply.started":"2022-08-07T13:43:18.949669Z","shell.execute_reply":"2022-08-07T13:43:19.061277Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the training process\n","metadata":{"papermill":{"duration":0.12533,"end_time":"2022-08-07T04:01:36.075601","exception":false,"start_time":"2022-08-07T04:01:35.950271","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"Validation loss\")\nax1.set_yticks(np.arange(0, 0.7, 0.1))\nax1.legend()\n\nax2.plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nax2.legend()\n\nlegend = plt.legend(loc='best')\nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":0.534563,"end_time":"2022-08-07T04:01:36.703155","exception":false,"start_time":"2022-08-07T04:01:36.168592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:43:20.013722Z","iopub.execute_input":"2022-08-07T13:43:20.014308Z","iopub.status.idle":"2022-08-07T13:44:10.076424Z","shell.execute_reply.started":"2022-08-07T13:43:20.014273Z","shell.execute_reply":"2022-08-07T13:44:10.075305Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the test","metadata":{"papermill":{"duration":0.133267,"end_time":"2022-08-07T04:01:36.982129","exception":false,"start_time":"2022-08-07T04:01:36.848862","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"To evaluate the performance of our model we will create a test generator to load the images from the input data directory and evaluate the results.","metadata":{"papermill":{"duration":0.092597,"end_time":"2022-08-07T04:01:37.172387","exception":false,"start_time":"2022-08-07T04:01:37.079790","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_datagen = image.ImageDataGenerator()\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe= test_df,\n    directory=base_path,\n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=1,\n    shuffle=False \n)","metadata":{"papermill":{"duration":1.19755,"end_time":"2022-08-07T04:01:38.463126","exception":false,"start_time":"2022-08-07T04:01:37.265576","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:44:38.305159Z","iopub.execute_input":"2022-08-07T13:44:38.305513Z","iopub.status.idle":"2022-08-07T13:44:40.428106Z","shell.execute_reply.started":"2022-08-07T13:44:38.305481Z","shell.execute_reply":"2022-08-07T13:44:40.427128Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"filenames = test_generator.filenames\nnb_samples = len(filenames)\n\n_, accuracy = model.evaluate_generator(test_generator, nb_samples)\n\nprint('Accuracy on test set = ',  round((accuracy * 100),2 ), '% ') ","metadata":{"papermill":{"duration":12.361663,"end_time":"2022-08-07T04:01:50.917505","exception":false,"start_time":"2022-08-07T04:01:38.555842","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:44:41.647302Z","iopub.execute_input":"2022-08-07T13:44:41.647718Z","iopub.status.idle":"2022-08-07T13:44:52.802368Z","shell.execute_reply.started":"2022-08-07T13:44:41.647682Z","shell.execute_reply":"2022-08-07T13:44:52.801307Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# We defined at the beginning of this notebook a dictionary that maps the categories number to names, but the train generator\n# generated it's own dictionary and it has assigned different numbers to our categories and the predictions made by the model \n# will be made using the genrator's dictionary.\n\ngen_label_map = test_generator.class_indices\ngen_label_map = dict((v,k) for k,v in gen_label_map.items())\nprint(gen_label_map)","metadata":{"papermill":{"duration":0.105304,"end_time":"2022-08-07T04:01:51.116136","exception":false,"start_time":"2022-08-07T04:01:51.010832","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:44:55.268451Z","iopub.execute_input":"2022-08-07T13:44:55.268819Z","iopub.status.idle":"2022-08-07T13:44:55.274997Z","shell.execute_reply.started":"2022-08-07T13:44:55.268787Z","shell.execute_reply":"2022-08-07T13:44:55.273175Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# get the model's predictions for the test set\npreds = model.predict_generator(test_generator, nb_samples)\n\n# Get the category with the highest predicted probability, the prediction is only the category's number and not name\npreds = preds.argmax(1)\n\n# Convert the predicted category's number to name \npreds = [gen_label_map[item] for item in preds]\n\n# Convert the pandas dataframe to a numpy matrix\nlabels = test_df['category'].to_numpy()\n\nprint(classification_report(labels, preds))","metadata":{"papermill":{"duration":7.880663,"end_time":"2022-08-07T04:01:59.092077","exception":false,"start_time":"2022-08-07T04:01:51.211414","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:44:56.139935Z","iopub.execute_input":"2022-08-07T13:44:56.140290Z","iopub.status.idle":"2022-08-07T13:45:03.988736Z","shell.execute_reply.started":"2022-08-07T13:44:56.140259Z","shell.execute_reply":"2022-08-07T13:45:03.987691Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"pip install gradio","metadata":{"papermill":{"duration":0.094612,"end_time":"2022-08-07T04:01:59.280378","exception":false,"start_time":"2022-08-07T04:01:59.185766","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-07T13:45:07.830955Z","iopub.execute_input":"2022-08-07T13:45:07.831314Z","iopub.status.idle":"2022-08-07T13:45:17.560180Z","shell.execute_reply.started":"2022-08-07T13:45:07.831285Z","shell.execute_reply":"2022-08-07T13:45:17.558837Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"import gradio as gr\nfrom tensorflow.keras.models import load_model\n \n# load model\nmodel = load_model('model6904.h5')\n\nclassnames = ['battery','cardboard','clothes','food','glass','medical','metal','paper','plastic','shoes']\n\n\n\ndef predict_image(img):\n  img_4d=img.reshape(-1,224, 224,3)\n  prediction=model.predict(img_4d)[0]\n  return {classnames[i]: float(prediction[i]) for i in range(10)}\n\n                \n\nimage = gr.inputs.Image(shape=(224, 224))\nlabel = gr.outputs.Label(num_top_classes=3)\narticle=\"<p style='text-align: center'>Made by Aditya Narendra with 🖤</p>\"\n\n\n\ngr.Interface(fn=predict_image, inputs=image,  title=\"Garbage Classifier V6- VGG16\",\n    description=\"This is a Garbage Classification Model Trained using MobileNetV2.Deployed to Hugging Faces using Gradio.\",outputs=label,article=article,enable_queue=True,interpretation='default').launch(share=\"True\")","metadata":{"execution":{"iopub.status.busy":"2022-08-07T13:45:45.553510Z","iopub.execute_input":"2022-08-07T13:45:45.554125Z","iopub.status.idle":"2022-08-07T13:45:49.268489Z","shell.execute_reply.started":"2022-08-07T13:45:45.554079Z","shell.execute_reply":"2022-08-07T13:45:49.267470Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}